{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID DOCUMENT_ID DOCUMENT_TYPE FILING_DATE          MODIFIED_AT  \\\n",
      "0  5243608   151501170            AR  2021-06-26  2021-07-04 00:48:21   \n",
      "1  5243690   150624238            AR  2021-06-26  2021-07-02 06:21:46   \n",
      "2  5260240   151500988            AR  2021-06-26  2021-07-03 10:48:41   \n",
      "3  3170254   143192570            AR  2019-12-31  2021-07-26 06:30:19   \n",
      "4  3186385   117880331            AR  2018-12-31  2021-07-26 06:37:52   \n",
      "5  6521828    88748390            AR  2017-12-31  2021-09-13 15:58:26   \n",
      "6  6521815   128706008            AR  2018-12-31  2021-09-13 18:03:10   \n",
      "7  8836144   173323495            AR  2022-09-20  2022-09-22 23:12:50   \n",
      "8  9046405   195677915            AR  2021-12-31  2022-11-12 03:23:38   \n",
      "\n",
      "                            DETAIL_JSON.company_name  \\\n",
      "0                 Joint-Stock Commercial Bank Rysgal   \n",
      "1  State Commercial Bank of Turkmenistan \"Turkmen...   \n",
      "2                 Joint-Stock Commercial Bank Rysgal   \n",
      "3                                     JSCB \"Senagat\"   \n",
      "4                               Turkmen-Turkish JSCB   \n",
      "5                Joint-stock commercial bank SENAGAT   \n",
      "6                Joint-stock commercial bank SENAGAT   \n",
      "7                 Joint-Stock Commercial Bank Rysgal   \n",
      "8  The State Bank for Foreign Economic Affairs of...   \n",
      "\n",
      "  DETAIL_JSON.parsing_status  avg_sent  sum_sent  hit_count  positive_hits  \\\n",
      "0                    SUCCESS -0.006933 -0.152516       1063            527   \n",
      "1                    SUCCESS  0.107112  0.535562        258            140   \n",
      "2                    WARNING -0.029118 -0.698841       1050            519   \n",
      "3                    WARNING  0.172174  1.033044        184            100   \n",
      "4                    SUCCESS -0.044254 -1.593157       1363            686   \n",
      "5                    SUCCESS  0.242301  2.665306        224            119   \n",
      "6                    SUCCESS  0.211561  1.692487        209            113   \n",
      "7                    WARNING -0.047435 -2.276889       1314            658   \n",
      "8                    SUCCESS -0.066851 -0.401109        965            458   \n",
      "\n",
      "   negative_hits  section_count  word_count  \n",
      "0            536             54       12556  \n",
      "1            118              5        3139  \n",
      "2            531             39       12084  \n",
      "3             84             18        2676  \n",
      "4            677             88       16389  \n",
      "5            105             19        2748  \n",
      "6             96             14        2451  \n",
      "7            656             48       28697  \n",
      "8            507             45       23033  \n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon May 18 19:20:21 2020\n",
    "\n",
    "@author: trevorsmith\n",
    "\n",
    "@ description: This is a sample script for \n",
    "1) how to read-in the Filing Reference Package from individual JSONs (new line delimited), \n",
    "combine them, and create a tabular view of the filing reference package information to be used as a look-up table for various metadata. \n",
    "\n",
    "2) how to read-in the Sentiment Scores Package from individual JSONs (new line delimited),\n",
    "combine them, and create a tabular view of the sentiment package information to investigate alpha.\n",
    "Below are examples of how to get the filing level sentiment scores, an individual section level's sentiment score, and\n",
    "an individual sub-section level's sentiment score. Each level will also have include 'ID' column, which can be used to join the sentiment\n",
    "score information to another level or to the the reference package to include metadata in an analysis. \n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ndjson\n",
    "import os\n",
    "import fnmatch\n",
    "\n",
    "\n",
    "# folder with the Reference, Data, Word Count, and Sentiment zipped files\n",
    "os.chdir('E:\\\\TM\\\\en-US')\n",
    "\n",
    "\n",
    "#### Filing Reference Package ####\n",
    "# create an empty list, combined_ref, and loop through each file and combine to combined_ref\n",
    "# combined ref will be a list of dictionaries\n",
    "combined_ref = []\n",
    "for file in os.listdir():\n",
    "    if(fnmatch.fnmatch(file, 'SP_FILING_REFERENCE*')):\n",
    "        with open(file,'r',encoding='utf_8') as ref:\n",
    "            ref = ndjson.load(ref)\n",
    "        combined_ref.extend(ref)    \n",
    " \n",
    "# normalize the reference package from its NDJSON form into a Data Frame - uses from pandas.io.json import json_normalize\n",
    "ref_normalize = pd.json_normalize(combined_ref)\n",
    "\n",
    "# change order of columns to reflect User Guide documentation\n",
    "ref_normalize = ref_normalize[['ID', 'DOCUMENT_ID','DOCUMENT_TYPE','FILING_DATE','MODIFIED_AT','DETAIL_JSON.company_name', 'DETAIL_JSON.parsing_status']]\n",
    "\n",
    "# convert the ID and document ID field to a string\n",
    "ref_normalize['ID'] = ref_normalize['ID'].apply(str)\n",
    "ref_normalize['DOCUMENT_ID'] = ref_normalize['DOCUMENT_ID'].apply(str)\n",
    "# ref_normalize['DETAIL_JSON.ISIN_active'] = ref_normalize['DETAIL_JSON.ISIN_active'].apply(str)\n",
    "# ref_normalize['DETAIL_JSON.SP_DocumentId'] = ref_normalize['DETAIL_JSON.SP_DocumentId'].apply(str)\n",
    "\n",
    "#### Sentiment Score Package ####\n",
    "# create an empty list, combined_sc, and loop through each file and combine to combined_sc\n",
    "# combined_sc will be a list of dictionaries\n",
    "combined_sc = []\n",
    "for file in os.listdir():\n",
    "    if(fnmatch.fnmatch(file, 'SP_FILING_SENTIMENT*')):\n",
    "        with open(file,'r',encoding='utf_8') as sc:# gzip 用来打开压缩文件中的数据\n",
    "            sc = ndjson.load(sc)\n",
    "        combined_sc.extend(sc)  # 加入最后\n",
    "\n",
    "\n",
    "## Filing Level Function\n",
    "# Function for calculating the sentiment figures at the main filing level - i.e., the aggregated sentiment figures for the actual\n",
    "# filing (EXCLUDING exhibits)\n",
    "#Parameter: filing_type - the filing type of the data in combined_sc (examples: '10-k', '10-q')\n",
    "def filing_level_func(filing_type):\n",
    "# column names of sentiment scores package based on User Guide documentation\n",
    "    column_names = ['ID','avg_sent','sum_sent','hit_count','positive_hits','negative_hits','section_count','word_count']\n",
    "# create empty list called filin g_level_list\n",
    "    filing_level_list = [[]]\n",
    "# loop through each element in combined_sc, check if the filing_type key exists in the 'SENTIMENT' key\n",
    "# if it does append doc_level_list with ID and the sentiment scores\n",
    "# if it does not, append doc_level_level with ID and NAs\n",
    "    for element in range(len(combined_sc)):\n",
    "        if combined_sc[element].get('SENTIMENT',{}).get(filing_type):\n",
    "            filing_level_list.append([str(combined_sc[element]['ID']), \n",
    "                          combined_sc[element]['SENTIMENT'][filing_type]['avg_sent'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type]['sum_sent'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type]['hit_count'], \n",
    "                          combined_sc[element]['SENTIMENT'][filing_type]['positive_hits'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type]['negative_hits'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type]['section_count'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type]['word_count']])\n",
    "        else:\n",
    "            filing_level_list.append([str(combined_sc[element]['ID']), np.nan, np.nan, np.nan, np.nan, np.nan, np.nan,np.nan])\n",
    "\n",
    "    # take contents of filing_level_list and put into a data frame called filing_level_df\n",
    "    filing_level_df = pd.DataFrame(filing_level_list[1:len(filing_level_list)], columns = column_names)    \n",
    "     \n",
    "    # convert the ID field to a string\n",
    "    filing_level_df['ID'] = filing_level_df['ID'].apply(str)\n",
    "    \n",
    "    # return the data frame\n",
    "    return filing_level_df\n",
    "\n",
    "\n",
    "## Section Level Function\n",
    "# Function for calculating the sentiment figures at the section level\n",
    "#Parameter: \n",
    "# filing_type - the filing type of the data in combined_sc (examples: 'AR', 'QR', 'SR')\n",
    "# section - the section of the filing_type of the data in combined_sc (examples: 'data', 'letter to shareholders', 'ceo report',etc)    \n",
    "def section_level_func(filing_type, section):\n",
    "# column names of sentiment scores package based on User Guide documentation\n",
    "    column_names = ['ID','avg_sent','sum_sent','hit_count','positive_hits','negative_hits','section_count','word_count']   \n",
    "# create empty list called section_level_list\n",
    "    section_level_list = [[]] \n",
    "# loop through each element in combined_sc, check if the section key exists in the 'SENTIMENT' key -> filing_type key\n",
    "# if it does append section_level_list with ID and the sentiment scores\n",
    "# if it does not, append section_level_level with ID and NAs\n",
    "    for element in range(len(combined_sc)):\n",
    "        if combined_sc[element].get('SENTIMENT',{}).get(filing_type,{}).get(section):\n",
    "            section_level_list.append([str(combined_sc[element]['ID']), \n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section]['avg_sent'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section]['sum_sent'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section]['hit_count'], \n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section]['positive_hits'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section]['negative_hits'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section]['section_count'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section]['word_count']])\n",
    "        else:\n",
    "            section_level_list.append([str(combined_sc[element]['ID']), np.nan, np.nan, np.nan, np.nan, np.nan, np.nan,np.nan])\n",
    "\n",
    "    # take contents of section_level_list and put into a data frame called section_level_df\n",
    "    section_level_df = pd.DataFrame(section_level_list[1:len(section_level_list)], columns = column_names)    \n",
    "    \n",
    "    # convert the ID field to a string\n",
    "    section_level_df['ID'] = section_level_df['ID'].apply(str)\n",
    "    \n",
    "    # return the data frame\n",
    "    return section_level_df\n",
    "\n",
    "\n",
    "## Sub-section Level Function  \n",
    "#Parameter: \n",
    "# filing_type - the filing type of the data in combined_sc (examples: '10-k', '10-q')\n",
    "# section - the section of the filing_type of the data in combined_sc (examples: 'data', 'letter to shareholders', 'ceo report',etc)    \n",
    "# sub-section - the sub-section of the section of the filing_type in combined_sc (examples: 'data','esg','risk', etc.)  \n",
    "def sub_level_func(filing_type, section, sub):\n",
    "# column names of sentiment scores package based on User Guide documentation\n",
    "    column_names = ['ID','avg_sent','sum_sent','hit_count','positive_hits','negative_hits','section_count','word_count']\n",
    "# create empty list called sub_level_list\n",
    "    sub_level_list = [[]] \n",
    "# loop through each element in combined_sc, check if the seub-section key exists in the 'SENTIMENT' key -> filing_type key -> section key\n",
    "# if it does append sub_level_list with ID and the sentiment scores\n",
    "# if it does not, append sub_level_list with ID and NAs\n",
    "    for element in range(len(combined_sc)):\n",
    "        if combined_sc[element].get('SENTIMENT',{}).get(filing_type,{}).get(section,{}).get(sub):\n",
    "            sub_level_list.append([str(combined_sc[element]['ID']), \n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section][sub]['avg_sent'], \n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section][sub]['sum_sent'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section][sub]['hit_count'], \n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section][sub]['positive_hits'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section][sub]['negative_hits'], \n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section][sub]['section_count'],\n",
    "                          combined_sc[element]['SENTIMENT'][filing_type][section][sub]['word_count']])\n",
    "      \n",
    "        else: sub_level_list.append([str(combined_sc[element]['ID']), np.nan, np.nan, np.nan, np.nan, np.nan, np.nan,np.nan])\n",
    "        \n",
    "    # take contents of sub_level_list and put into a data frame called sub_level_df\n",
    "    sub_level_df = pd.DataFrame(sub_level_list[1:len(sub_level_list)], columns = column_names)    \n",
    "    \n",
    "    # convert the ID field to a string\n",
    "    sub_level_df['ID'] = sub_level_df['ID'].apply(str)\n",
    "    \n",
    "    # return the data frame\n",
    "    return sub_level_df\n",
    "\n",
    "## Examples of calling functions\n",
    "# get the AR sentiment data at the filing level\n",
    "ars = filing_level_func('ar')\n",
    "\n",
    "# Join reference information with sentiment metrics\n",
    "combined = pd.merge(left = ref_normalize, right = ars, on = 'ID')\n",
    "\n",
    "print(combined)\n",
    "\n",
    "# combined.groupy({})\n",
    "# type(combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practicum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3e1d988fd02f3af9046135819fd37ed5d41f46c7de55723b70daeaf254c35f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
